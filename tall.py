import os
import cv2
import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from sklearn.preprocessing import StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
import random
from typing import List, Tuple, Dict, Optional
import logging
from dataclasses import dataclass
import warnings

warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    """ì„¤ì • í´ë˜ìŠ¤"""
    # í•„ìˆ˜ ì„¤ì • (GTê°€ ìˆëŠ” ê²½ìš°)
    csv_file: Optional[str] = None  # GT ë¹„êµìš© (ì„ íƒì‚¬í•­)
    csv_file = r'C:\Users\qkrgu\PycharmProjects\cap\venv\all\call_loc.csv'
    image_dir = r'C:\Users\qkrgu\PycharmProjects\cap\venv\all'
    model_path: str = 'landmark_model.pth'

    # ì²˜ë¦¬ ì„¤ì •
    image_size: int = 224
    mae_threshold: float = 2.0
    exclude_idx: List[int] = None
    include_idx: List[int] = None

    def __post_init__(self):
        if self.exclude_idx is None:
            self.exclude_idx = [4, 5]
        if self.include_idx is None:
            self.include_idx = [i for i in range(22) if i not in self.exclude_idx]


class LandmarkPredictor:
    """ëœë“œë§ˆí¬ ì˜ˆì¸¡ í´ë˜ìŠ¤"""

    def __init__(self, model_path: str, device: str = None):
        self.device = torch.device(device or ("cuda" if torch.cuda.is_available() else "cpu"))
        self.model = self._load_model(model_path)

    def _load_model(self, model_path: str):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            from model import MyLandmarkModel
            model = MyLandmarkModel().to(self.device)
            model.load_state_dict(torch.load(model_path, map_location=self.device))
            model.eval()
            return model
        except ImportError:
            logger.error("model.pyì—ì„œ MyLandmarkModelì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            raise

    def predict_single(self, image_path: str, image_size: int = 224) -> Optional[np.ndarray]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ëœë“œë§ˆí¬ ì˜ˆì¸¡"""
        try:
            img = cv2.imread(image_path)
            if img is None:
                return None

            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            return self.predict_from_array(img_rgb, image_size)
        except Exception as e:
            logger.warning(f"ì˜ˆì¸¡ ì‹¤íŒ¨ {image_path}: {e}")
            return None

    def predict_from_array(self, image: np.ndarray, image_size: int = 224) -> np.ndarray:
        """numpy ë°°ì—´ì—ì„œ ëœë“œë§ˆí¬ ì˜ˆì¸¡"""
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        img_resized = cv2.resize(image, (image_size, image_size))
        img_tensor = torch.from_numpy(img_resized / 255.).permute(2, 0, 1)
        img_tensor = (img_tensor - 0.5) / 0.5
        img_tensor = img_tensor.unsqueeze(0).float().to(self.device)

        # ì˜ˆì¸¡
        with torch.no_grad():
            pred = self.model(img_tensor).cpu().squeeze(0).numpy().reshape(-1, 2)

        return pred


class FeatureExtractor:
    """íŠ¹ì§• ì¶”ì¶œ í´ë˜ìŠ¤"""

    @staticmethod
    def angle_between(p1: np.ndarray, p2: np.ndarray, p3: np.ndarray) -> float:
        """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
        a = np.array(p1) - np.array(p2)
        b = np.array(p3) - np.array(p2)
        cosine_angle = np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8)
        return np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))

    @staticmethod
    def curvature_score(pts: List[np.ndarray]) -> float:
        """ê³¡ë¥  ì ìˆ˜ ê³„ì‚°"""
        p1, p2, p3, p4 = pts
        angle1 = FeatureExtractor.angle_between(p1, p2, p3)
        angle2 = FeatureExtractor.angle_between(p2, p3, p4)
        return (angle1 + angle2) / 2

    @staticmethod
    def euclidean_distance(p1: np.ndarray, p2: np.ndarray) -> float:
        """ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°"""
        return np.linalg.norm(np.array(p1) - np.array(p2))

    @staticmethod
    def extract_features(landmarks: np.ndarray) -> Dict[str, float]:
        """íŠ¹ì§• ì¶”ì¶œ (ëœë“œë§ˆí¬ë§Œìœ¼ë¡œ)"""
        landmarks = np.array(landmarks).reshape(-1, 2)
        feats = {}

        # ê¸°ì¡´ íŠ¹ì§•ë“¤ (ì›ë³¸ ì½”ë“œ ê¸°ë°˜)
        try:
            feats['front_curvature_L'] = FeatureExtractor.curvature_score([
                landmarks[2], landmarks[5], landmarks[6], landmarks[7]
            ])
            feats['front_angle_L'] = FeatureExtractor.angle_between(
                landmarks[2], landmarks[5], landmarks[6]
            )
            feats['tail_curvature_L'] = FeatureExtractor.curvature_score([
                landmarks[0], landmarks[4], landmarks[5], landmarks[6]
            ])
            feats['tail_angle_L'] = FeatureExtractor.angle_between(
                landmarks[0], landmarks[4], landmarks[5]
            )
            feats['front_curvature_R'] = FeatureExtractor.curvature_score([
                landmarks[3], landmarks[13], landmarks[14], landmarks[15]
            ])
            feats['front_angle_R'] = FeatureExtractor.angle_between(
                landmarks[3], landmarks[13], landmarks[14]
            )
            feats['tail_curvature_R'] = FeatureExtractor.curvature_score([
                landmarks[2], landmarks[12], landmarks[13], landmarks[14]
            ])
            feats['tail_angle_R'] = FeatureExtractor.angle_between(
                landmarks[2], landmarks[12], landmarks[13]
            )

            feats['eye_length_L'] = FeatureExtractor.euclidean_distance(landmarks[0], landmarks[6])
            feats['eye_length_R'] = FeatureExtractor.euclidean_distance(landmarks[3], landmarks[14])
            feats['asymmetry'] = abs(feats['eye_length_L'] - feats['eye_length_R'])

        except IndexError:
            logger.warning("ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ ì˜¤ë¥˜ - ê¸°ë³¸ê°’ ì‚¬ìš©")
            for key in ['front_curvature_L', 'front_angle_L', 'tail_curvature_L', 'tail_angle_L',
                        'front_curvature_R', 'front_angle_R', 'tail_curvature_R', 'tail_angle_R',
                        'eye_length_L', 'eye_length_R', 'asymmetry']:
                feats[key] = 0.0

        return feats


class SimilaritySearcher:
    """ìœ ì‚¬ë„ ê²€ìƒ‰ í´ë˜ìŠ¤"""

    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_matrix = None
        self.similarity_matrix = None
        self.fitted = False

    def fit(self, landmarks_list: List[np.ndarray]) -> None:
        """íŠ¹ì§• í–‰ë ¬ êµ¬ì„± ë° ìœ ì‚¬ë„ ê³„ì‚°"""
        features = []
        for landmarks in landmarks_list:
            feat = FeatureExtractor.extract_features(landmarks)
            features.append(feat)

        if not features:
            logger.error("íŠ¹ì§•ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        feature_df = pd.DataFrame(features)

        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_df = feature_df.copy()
        important_features = ['front_curvature_L', 'front_angle_L',
                              'front_curvature_R', 'front_angle_R']
        for feat in important_features:
            if feat in weighted_df.columns:
                weighted_df[feat] *= 2.0

        # ì •ê·œí™”
        X_scaled = self.scaler.fit_transform(weighted_df.fillna(0))

        self.feature_matrix = X_scaled
        self.similarity_matrix = cosine_similarity(X_scaled)
        self.fitted = True

    def find_similar(self, query_idx: int, topk: int = 10) -> List[Tuple[int, float]]:
        """ìœ ì‚¬í•œ ìƒ˜í”Œ ì°¾ê¸°"""
        if not self.fitted:
            raise ValueError("ë¨¼ì € fit() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ì£¼ì„¸ìš”.")

        similarities = self.similarity_matrix[query_idx]
        top_indices = np.argsort(similarities)[::-1][:topk + 1]

        return [(idx, similarities[idx]) for idx in top_indices]


class IntegratedLandmarkSystem:
    """í†µí•© ëœë“œë§ˆí¬ ì‹œìŠ¤í…œ - ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ì‘ë™"""

    def __init__(self, config: Config):
        self.config = config
        self.predictor = LandmarkPredictor(config.model_path)
        self.searcher = SimilaritySearcher()

        # ê²°ê³¼ ì €ì¥
        self.image_files = []
        self.predictions = []
        self.ground_truths = []  # GTê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ
        self.maes = []  # GTê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ

    def process_images_from_directory(self, image_filter: str = None) -> None:
        """ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ë“¤ì„ ì²˜ë¦¬"""
        image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']

        for filename in os.listdir(self.config.image_dir):
            if any(filename.lower().endswith(ext) for ext in image_extensions):
                # í•„í„° ì ìš© (ì˜ˆ: 'after' í¬í•¨ ì´ë¯¸ì§€ë§Œ)
                if image_filter and image_filter not in filename:
                    continue

                image_path = os.path.join(self.config.image_dir, filename)

                # ëœë“œë§ˆí¬ ì˜ˆì¸¡
                landmarks = self.predictor.predict_single(image_path, self.config.image_size)

                if landmarks is not None:
                    self.image_files.append(filename)
                    self.predictions.append(landmarks)
                    logger.info(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {filename}")
                else:
                    logger.warning(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨: {filename}")

        logger.info(f"ì´ {len(self.predictions)}ê°œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ")

        # ìœ ì‚¬ë„ ê²€ìƒ‰ ëª¨ë¸ í•™ìŠµ
        if self.predictions:
            self.searcher.fit(self.predictions)
            logger.info("ìœ ì‚¬ë„ ê²€ìƒ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

    def process_with_ground_truth(self) -> None:
        """GTê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ì›ë³¸ í‰ê°€ ì½”ë“œ ê¸°ëŠ¥)"""
        if not self.config.csv_file:
            logger.error("CSV íŒŒì¼ ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        df = pd.read_csv(self.config.csv_file)

        for idx, row in df.iterrows():
            filename = row['filename']
            image_path = os.path.join(self.config.image_dir, filename)

            if not os.path.exists(image_path):
                continue

            # ëœë“œë§ˆí¬ ì˜ˆì¸¡
            landmarks = self.predictor.predict_single(image_path, self.config.image_size)

            if landmarks is not None:
                # GT ì¢Œí‘œ ì¶”ì¶œ
                coords = row.iloc[0:44].values.astype(np.float32).reshape(-1, 2)
                gt_landmarks = coords[self.config.include_idx] / self.config.image_size

                # MAE ê³„ì‚°
                mae = np.mean(np.abs(gt_landmarks - landmarks)) * self.config.image_size

                self.image_files.append(filename)
                self.predictions.append(landmarks)
                self.ground_truths.append(gt_landmarks)
                self.maes.append(mae)

                status = "â— ì˜¤ì°¨ í¼" if mae > self.config.mae_threshold else "âœ… ì •ìƒ"
                logger.info(f"{status} {filename} | MAE: {mae:.2f}")

        # ìœ ì‚¬ë„ ê²€ìƒ‰ ëª¨ë¸ í•™ìŠµ
        if self.predictions:
            self.searcher.fit(self.predictions)
            logger.info("ìœ ì‚¬ë„ ê²€ìƒ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")

    def find_similar_images(self, query_idx: int, topk: int = 10) -> List[Tuple[int, float]]:
        """ìœ ì‚¬í•œ ì´ë¯¸ì§€ ì°¾ê¸°"""
        return self.searcher.find_similar(query_idx, topk)

    def visualize_results(self, query_idx: int, topk: int = 5):
        """ê²°ê³¼ ì‹œê°í™”"""
        if query_idx >= len(self.predictions):
            logger.error(f"ì¸ë±ìŠ¤ {query_idx}ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤.")
            return

        similar_results = self.find_similar_images(query_idx, topk)

        fig, axes = plt.subplots(2, min(6, len(similar_results)), figsize=(20, 8))
        if len(similar_results) == 1:
            axes = axes.reshape(2, 1)

        for i, (idx, similarity) in enumerate(similar_results[:6]):
            # ì›ë³¸ ì´ë¯¸ì§€
            image_path = os.path.join(self.config.image_dir, self.image_files[idx])
            img = Image.open(image_path)
            axes[0, i].imshow(img)
            title = f"Query" if i == 0 else f"Sim: {similarity:.3f}"
            axes[0, i].set_title(title)
            axes[0, i].axis('off')

            # ëœë“œë§ˆí¬ ì‹œê°í™”
            img_resized = np.array(img.resize((self.config.image_size, self.config.image_size)))
            axes[1, i].imshow(img_resized)

            # ì˜ˆì¸¡ëœ ëœë“œë§ˆí¬
            pred = self.predictions[idx] * self.config.image_size
            axes[1, i].plot(pred[:, 0], pred[:, 1], 'rx', markersize=4, label='Pred')

            # GTê°€ ìˆëŠ” ê²½ìš°
            if self.ground_truths and idx < len(self.ground_truths):
                gt = self.ground_truths[idx] * self.config.image_size
                axes[1, i].plot(gt[:, 0], gt[:, 1], 'go', markersize=3, label='GT')
                mae_text = f"MAE: {self.maes[idx]:.2f}" if self.maes else ""
                axes[1, i].set_title(mae_text)
            else:
                axes[1, i].set_title("Predicted")

            axes[1, i].axis('off')
            axes[1, i].legend(fontsize=8)

        plt.tight_layout()
        plt.show()

    def save_predictions_to_csv(self, output_path: str = "predicted_landmarks.csv"):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
        if not self.predictions:
            logger.error("ì €ì¥í•  ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        data = []
        for i, (filename, landmarks) in enumerate(zip(self.image_files, self.predictions)):
            row = {'filename': filename}

            # ëœë“œë§ˆí¬ ì¢Œí‘œ ì¶”ê°€
            for j, (x, y) in enumerate(landmarks):
                row[f'pt{j + 1}_x'] = x * self.config.image_size
                row[f'pt{j + 1}_y'] = y * self.config.image_size

            # MAE ì¶”ê°€ (GTê°€ ìˆëŠ” ê²½ìš°)
            if self.maes and i < len(self.maes):
                row['mae'] = self.maes[i]

            data.append(row)

        df = pd.DataFrame(data)
        df.to_csv(output_path, index=False)
        logger.info(f"ì˜ˆì¸¡ ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    config = Config()
    system = IntegratedLandmarkSystem(config)

    print("=== í†µí•© ëœë“œë§ˆí¬ ì‹œìŠ¤í…œ ===")
    print("1. ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ëœë“œë§ˆí¬ ì˜ˆì¸¡ + ìœ ì‚¬ë„ ê²€ìƒ‰")
    print("2. GTì™€ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í‰ê°€ + ìœ ì‚¬ë„ ê²€ìƒ‰")

    mode = input("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš” (1 ë˜ëŠ” 2): ").strip()

    if mode == "1":
        # ì´ë¯¸ì§€ë§Œìœ¼ë¡œ ì²˜ë¦¬
        filter_text = input("í•„í„°í•  í…ìŠ¤íŠ¸ (ì˜ˆ: 'after', ì—†ìœ¼ë©´ ì—”í„°): ").strip()
        image_filter = filter_text if filter_text else None

        logger.info("ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘...")
        system.process_images_from_directory(image_filter)

        # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        system.save_predictions_to_csv("predicted_landmarks.csv")

    elif mode == "2":
        # GTì™€ í•¨ê»˜ ì²˜ë¦¬
        csv_path = input(f"CSV íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: {config.csv_file}): ").strip()
        if csv_path:
            config.csv_file = csv_path

        logger.info("GTì™€ í•¨ê»˜ ì²˜ë¦¬ ì‹œì‘...")
        system.process_with_ground_truth()

        # ì¢‹ì€/ë‚˜ìœ ìƒ˜í”Œ ë¶„ë¥˜
        if system.maes:
            good_samples = [f for f, mae in zip(system.image_files, system.maes)
                            if mae <= config.mae_threshold]
            bad_samples = [f for f, mae in zip(system.image_files, system.maes)
                           if mae > config.mae_threshold]

            print(f"âœ… ì¢‹ì€ ìƒ˜í”Œ: {len(good_samples)}ê°œ")
            print(f"â— ë‚˜ìœ ìƒ˜í”Œ: {len(bad_samples)}ê°œ")

    # ìœ ì‚¬ë„ ê²€ìƒ‰ ë°ëª¨
    if system.predictions:
        print(f"\nì´ {len(system.predictions)}ê°œ ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰ ê°€ëŠ¥")

        # ëœë¤ ìƒ˜í”Œ ì‹œê°í™”
        demo_count = min(3, len(system.predictions))
        random_indices = random.sample(range(len(system.predictions)), demo_count)

        for idx in random_indices:
            print(f"\nğŸ” Query: {system.image_files[idx]}")
            system.visualize_results(idx, topk=5)


if __name__ == "__main__":
    main()