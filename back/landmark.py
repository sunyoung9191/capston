import torch
import torch.nn as nn
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
from view_pic_feature import FeatureExtractor

class MyLandmarkModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2),
        )
        self.classifier = nn.Sequential(
            nn.Linear(64 * 28 * 28, 512),
            nn.ReLU(),
            nn.Linear(512, 44)  # ğŸ”¥ 22ê°œ ì¢Œí‘œ * 2 = 44
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x



# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_landmark_model(model_path):
    from model import CNNLandmarkModel  # ì˜ˆì€ì´ì˜ CNN êµ¬ì¡°ë¼ë©´ ì´ë ‡ê²Œ
    model = CNNLandmarkModel()          # í´ë˜ìŠ¤ ì´ë¦„ ë°”ë€Œì—ˆìœ¼ë©´ ë§ê²Œ ìˆ˜ì •!
    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))
    model.eval()
    return model


# ì´ë¯¸ì§€ë¡œë¶€í„° ëœë“œë§ˆí¬ ì˜ˆì¸¡
def predict_landmarks(model, image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    input_tensor = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(input_tensor)
    coords = output.view(-1, 2).cpu().numpy()
    return coords
